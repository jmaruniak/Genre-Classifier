{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bizarre-tobago",
   "metadata": {},
   "source": [
    "# Notebook for generating attribution maps and masked spectrograms out of provided songs from 'data/songs' directory or out of examples from extracted feature sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brutal-floor",
   "metadata": {},
   "outputs": [],
   "source": [
    "import import_ipynb\n",
    "import cnn_genre_classifier as mgr\n",
    "import IPython.display as ipd\n",
    "import librosa\n",
    "import numpy as np\n",
    "import torch\n",
    "from captum.attr import IntegratedGradients"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "british-compensation",
   "metadata": {},
   "source": [
    "# Loading a music sample from test set (requires extracted feature file from dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "liquid-consent",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load test set, model, and print confusion matrix in order to choose what example to process\n",
    "dataset = torch.load(\"./data/feature_sets/spectro10_normalized.pth\")\n",
    "X_test = dataset['X_test']\n",
    "y_test = dataset['y_test']\n",
    "scale_min = dataset['scale_min']\n",
    "scale_max = dataset['scale_max']\n",
    "\n",
    "model = mgr.load_model(\"./data/saved_models/model-spectro10-epoch15-batch64_512-norm.pth\")\n",
    "model_predictions = model.get_predictions(X_test)\n",
    "matrix = mgr.create_confusion_matrix(model_predictions, y_test)\n",
    "mgr.plot_confusion_matrix(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mexican-ceremony",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using the confusion matrix, print indexes of all samples between selected pair of predicted_class/true_class\n",
    "\n",
    "# 0-Blues, 1-Classical, 2-Country, 3-Disco, 4-HipHop, 5-Jazz, 6-Metal, 7-Pop, 8-Reggae, 9-Rock\n",
    "true_class = 0\n",
    "predicted_class = 5\n",
    "\n",
    "for index, (p, q) in enumerate(zip(model_predictions.argmax(dim=1).type(torch.LongTensor), y_test.type(torch.LongTensor))):\n",
    "    if (q == true_class and p == predicted_class):\n",
    "        print(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "centered-messenger",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set index based on which example you want to apply attributions on\n",
    "index = 1177\n",
    "\n",
    "# reconstruct original signal and prepare variables for attribution methods\n",
    "X = X_test[index].unsqueeze(0)\n",
    "X_db = mgr.unscale_input(X.squeeze(), scale_min, scale_max).numpy()\n",
    "X_amplitude = librosa.db_to_amplitude(X_db)\n",
    "reconstruction = librosa.griffinlim(X_amplitude, hop_length=512, win_length=1024)\n",
    "sample_rate = 22050\n",
    "prediction = model_predictions.argmax(dim=1).type(torch.LongTensor)[index]\n",
    "\n",
    "# listen to the segment\n",
    "ipd.Audio(reconstruction, rate=22050)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fourth-boutique",
   "metadata": {},
   "source": [
    "# Loading a music sample from 'songs' folder in data directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "periodic-karaoke",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load and process specific segment from a song\n",
    "file_path = \"./data/songs/rock.00030.wav\"\n",
    "segment = 1\n",
    "\n",
    "#exract spectrogram from selected segment using fourier transform. Same process\n",
    "#that was used to extract features from processing of GTZAN dataset\n",
    "start = 66150 * (segment - 1)\n",
    "finish = 66150 * segment\n",
    "signal, sample_rate = librosa.load(file_path, sr=22050)\n",
    "stft = librosa.stft(signal[start:finish], n_fft=1024, hop_length=512)\n",
    "X_power = np.abs(stft) ** 2\n",
    "X_db = librosa.power_to_db(X_power)\n",
    "X_amplitude = librosa.db_to_amplitude(X_db)\n",
    "\n",
    "# load model and feed him a normalized example to get predicted class\n",
    "model = mgr.load_model(\"./data/saved_models/model-spectro10-epoch15-batch64_512-norm.pth\").cpu().eval()\n",
    "normalization_spectrograms = torch.load(\"./data/songs/accessory/normalization_spectrograms.pth\")\n",
    "scale_min = normalization_spectrograms['scale_min']\n",
    "scale_max = normalization_spectrograms['scale_max']\n",
    "X = mgr.scale_input(torch.Tensor(X_db), scale_min, scale_max)[0].unsqueeze(0).unsqueeze(0)\n",
    "output = model(X)\n",
    "prediction = torch.argmax(output)\n",
    "classes = torch.load(\"./data/songs/accessory/classes.pth\")['classes']\n",
    "print(\"Predicted: {} ({})\".format(classes[prediction], prediction))\n",
    "\n",
    "# listen to the segment\n",
    "ipd.Audio(signal[start:finish], rate=sample_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comic-permit",
   "metadata": {},
   "source": [
    "# Guided Gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "computational-intersection",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate guided gradients and their pos/neg saliency maps in respect to model prediction\n",
    "# reconstruct signal using guided gradients positive saliency as spectral mask\n",
    "\n",
    "model = mgr.load_model(\"./data/saved_models/model-spectro10-epoch15-batch64_512-norm.pth\").cpu().eval()\n",
    "gbp = mgr.GuidedBackprop(model)\n",
    "guided_grads = gbp.generate_gradients(X, prediction)\n",
    "pos_sal_gbp, _ = mgr.get_positive_negative_saliency(guided_grads)\n",
    "X_masked_gbp = X_amplitude * pos_sal_gbp\n",
    "reconstruction_gbp = librosa.griffinlim(X_masked_gbp, hop_length=512, win_length=1024)\n",
    "X_masked_gbp = librosa.amplitude_to_db(X_masked_gbp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "literary-discipline",
   "metadata": {},
   "outputs": [],
   "source": [
    "mgr.plot_spectrogram(X_db, sample_rate, 512, title=\"Original spectrum\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "greater-candy",
   "metadata": {},
   "outputs": [],
   "source": [
    "mgr.plot_spectrogram(pos_sal_gbp, sample_rate, 512, title=\"GBP attribution map\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "forbidden-minneapolis",
   "metadata": {},
   "outputs": [],
   "source": [
    "mgr.plot_spectrogram(X_masked_gbp, sample_rate, 512, title=\"GBP masked spectrum\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bulgarian-requirement",
   "metadata": {},
   "outputs": [],
   "source": [
    "ipd.Audio(reconstruction_gbp, rate=sample_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "imposed-willow",
   "metadata": {},
   "source": [
    "# Integrated Gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ordered-discrimination",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate integrated gradients and their pos/neg saliency maps in respect to model prediction\n",
    "# reconstruct signal using integrated gradients positive saliency as spectral mask\n",
    "\n",
    "model = mgr.load_model(\"./data/saved_models/model-spectro10-epoch15-batch64_512-norm.pth\").cpu().eval()\n",
    "baseline = torch.zeros(1, 1, 513, 130)\n",
    "ig = IntegratedGradients(model)\n",
    "integrated_grads = ig.attribute(X, baseline, prediction).squeeze().numpy()\n",
    "pos_sal_ig, _ = mgr.get_positive_negative_saliency(integrated_grads)\n",
    "X_masked_ig = X_amplitude * pos_sal_ig\n",
    "reconstruction_ig = librosa.griffinlim(X_masked_ig, hop_length=512, win_length=1024)\n",
    "X_masked_ig = librosa.amplitude_to_db(X_masked_ig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "immune-diameter",
   "metadata": {},
   "outputs": [],
   "source": [
    "mgr.plot_spectrogram(X_db, sample_rate, 512, title=\"Original spectrum\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "blocked-south",
   "metadata": {},
   "outputs": [],
   "source": [
    "mgr.plot_spectrogram(pos_sal_ig, sample_rate, 512, title=\"IG attribution map\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "functional-income",
   "metadata": {},
   "outputs": [],
   "source": [
    "mgr.plot_spectrogram(X_masked_ig, sample_rate, 512, title=\"IG masked spectrum\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aware-scoop",
   "metadata": {},
   "outputs": [],
   "source": [
    "ipd.Audio(reconstruction_ig, rate=sample_rate)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
